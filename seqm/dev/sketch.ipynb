{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  y1        x1\n",
      "2000-01-01 -0.002909 -0.000349\n",
      "2000-01-02 -0.014925  0.003193\n",
      "2000-01-03 -0.001564  0.003032\n",
      "2000-01-04 -0.001951 -0.014094\n",
      "2000-01-05  0.009174 -0.005012\n",
      "...              ...       ...\n",
      "2002-09-22 -0.008811  0.001785\n",
      "2002-09-23  0.022967  0.008881\n",
      "2002-09-24 -0.006981  0.000270\n",
      "2002-09-25  0.010244  0.013733\n",
      "2002-09-26 -0.015992 -0.001439\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                  y1        x1\n",
      "2000-01-01  0.003965 -0.010379\n",
      "2000-01-02 -0.006044  0.015378\n",
      "2000-01-03 -0.007262  0.014449\n",
      "2000-01-04  0.003556 -0.001425\n",
      "2000-01-05 -0.005290 -0.002867\n",
      "...              ...       ...\n",
      "2002-09-22 -0.014068 -0.017610\n",
      "2002-09-23 -0.008269 -0.002185\n",
      "2002-09-24  0.005935  0.008227\n",
      "2002-09-25  0.013204  0.013438\n",
      "2002-09-26 -0.011300 -0.012476\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def linear(n=1000,a=0,b=0.1,start_date='2000-01-01'):\n",
    "    x=np.random.normal(0,0.01,n)\n",
    "    y=a+b*x+np.random.normal(0,0.01,n)\n",
    "    dates=pd.date_range(start_date,periods=n,freq='D')\n",
    "    data=pd.DataFrame(np.hstack((y[:,None],x[:,None])),columns=['y1','x1'],index=dates)\n",
    "    return data\n",
    "df1 = linear(n=1000,a=0,b=0.1,start_date='2000-01-01')\n",
    "df2 = linear(n=1000,a=0,b=0.1,start_date='2000-01-01')\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract classes\n",
    "\n",
    "class PredictiveDistribution:\n",
    "    def __init__(self, mean, cov):\n",
    "        self.mean = mean\n",
    "        self.cov = cov\n",
    "    \n",
    "    def get_weight(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class Weight:\n",
    "    def __init__(self, w:np.ndarray):\n",
    "        self.w = w\n",
    "\n",
    "class Model(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def estimate(self,y: np.ndarray, **kwargs):\n",
    "        \"\"\"Subclasses must implement this method\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_weight(self, **kwargs) -> Weight:\n",
    "        \"\"\"Subclasses must implement this method\"\"\"\n",
    "        pass\n",
    "\n",
    "# Portfolio Model class template\n",
    "class PortfolioModel(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def view(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, **kwargs):\n",
    "        \"\"\"Subclasses must implement this method\"\"\"\n",
    "        pass\n",
    "\n",
    "# Data Transform template\n",
    "class Transform(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def view(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, **kwargs):\n",
    "        \"\"\"Subclasses must implement this method\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, **kwargs):\n",
    "        \"\"\"Subclasses must implement this method\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def inverse_transform(self, **kwargs):\n",
    "        \"\"\"Subclasses must implement this method\"\"\"\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single dataset..\n",
    "\n",
    "dataset = Dataset(df)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = ModelPipe(model, transforms)\n",
    "model_pipe.estimate(dataset)\n",
    "\n",
    "model_pipe.evaluate(dataset_test)\n",
    "# best to store it all on model_pipe!\n",
    "# model_pipe acts on data...\n",
    "# more similar to first version!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# how should a workflow operate?\n",
    "# -----\n",
    "# what does a model pipeline has?\n",
    "# - can act on different datasets\n",
    "# - if not specified, just applied the same model to all datasets, otherwise needs to be compatible \n",
    "# with the data\n",
    "# - if specified, join all data to train it as a \"master\" model\n",
    "# - data can suffer transformations \n",
    "# - has a portfolio model that specified how the models should be joined!\n",
    "# this portfolio model can take into account as well strategy performance statistics\n",
    "# to make the decision on how to allocate\n",
    "# ALSO\n",
    "# must specify how does the models are trained and evaluated!\n",
    "\n",
    "# what do we have?\n",
    "# - dataset\n",
    "# - portfolio model\n",
    "# - transforms\n",
    "# - model\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class ModelPipe:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def estimate(self, dataset:Dataset):\n",
    "        '''\n",
    "        After estimate the model pipe is configure\n",
    "        to work on data that has the same format        \n",
    "        '''        \n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, dataset:Dataset):\n",
    "        '''\n",
    "        Need to check if the input dataset \n",
    "        makes sense to the one it was trained on\n",
    "        '''\n",
    "        assert self.estimate_dataset.is_compatible(dataset), \"can only evaluate in compatible datasets\"\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def get_weight(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "# create model pipe\n",
    "\n",
    "# when we run estimate we can do\n",
    "model.estimate(dataset)\n",
    "# and the model get trained\n",
    "\n",
    "# when we run evaluate we can do\n",
    "out = model.evaluate(dataset)\n",
    "# and we get the output of an estimation\n",
    "\n",
    "# so, when we do cvbt, the model can make many call to estimate\n",
    "# but internally it builds the splits and the calls to estimate\n",
    "# and evaluate necessary\n",
    "out = model.cvbt(dataset)\n",
    "\n",
    "# WHAT WE NEED?\n",
    "# dataset must make sense for the model that was defined...\n",
    "# add checks for this?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for live we have a pd.DataFrame and a trained model and we\n",
    "# need to call something like\n",
    "model = load_model('filemodel.pkl')\n",
    "model.get_weight(dataset) \n",
    "# or should it be \n",
    "model.live(dataset)\n",
    "# ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create dataset from input dataframes\n",
    "dataset = Dataset({'dataset1':df1, 'dataset2':df2})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
